{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(Path(\"..\").resolve().as_posix())\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, HttpUrl\n",
    "from typing import List, Optional\n",
    "import requests\n",
    "from datasets import Dataset, Image\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets_path = Path(\"fashion_twitter_raw/raw_fashion_twitter.jsonl\")\n",
    "images_path = Path(\"fashion_twitter_raw/images\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommendations(BaseModel):\n",
    "    problems: List[str]\n",
    "    fixes: List[str]\n",
    "    positives: Optional[List[str]] = []\n",
    "    advice: str\n",
    "\n",
    "class Tweet(BaseModel):\n",
    "    id: str\n",
    "    image_url: HttpUrl\n",
    "    description: str\n",
    "    recommendations: Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with raw_tweets_path.open(\"r\") as f:\n",
    "    tweets = [Tweet.model_validate_json(line) for line in f.readlines()]\n",
    "\n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0].model_dump_json(include=[\"description\", \"recommendations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Download each image\n",
    "for tweet in tweets:\n",
    "    response = requests.get(tweet.image_url)\n",
    "    if response.status_code == 200:\n",
    "        with images_path.joinpath(f\"{tweet.id}.jpg\").open(\"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {tweet.id}.jpg\")\n",
    "    else:\n",
    "        print(f\"Failed to download image from {tweet.image_url}\")\n",
    "\n",
    "print(\"All images downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = defaultdict(list)\n",
    "\n",
    "for tweet in tweets:\n",
    "    dataset_dict[\"image\"].append(images_path.joinpath(f\"{tweet.id}.jpg\").as_posix())\n",
    "    dataset_dict[\"json\"].append(tweet.model_dump_json(include=[\"description\", \"recommendations\"]))\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(dataset_dict).cast_column(\"image\", Image())\n",
    "dataset.save_to_disk(\"fashion_twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"extract JSON.\"\n",
    "\n",
    "class ImageJSONCollatorWithPadding:\n",
    "\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        json_dicts = [json.loads(example[\"json\"]) for example in examples]\n",
    "        labels = [self.json2token(json_dict) for json_dict in json_dicts]\n",
    "\n",
    "        images = [example[\"image\"] for example in examples]\n",
    "\n",
    "        images = [\n",
    "            torch.cat([image, image, image], dim=0) if image.shape[0] == 1 else image\n",
    "            for image in images\n",
    "        ]\n",
    "\n",
    "        texts = [PROMPT for _ in range(len(examples))]\n",
    "\n",
    "        tokens = self.processor(\n",
    "            text=texts,\n",
    "            images=images,\n",
    "            suffix=labels,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "        )\n",
    "        return tokens\n",
    "\n",
    "    def json2token(self, obj, sort_json_key: bool = True):\n",
    "        \"\"\"\n",
    "        Convert an ordered JSON object into a token sequence\n",
    "        \"\"\"\n",
    "        if type(obj) == dict:\n",
    "            if len(obj) == 1 and \"text_sequence\" in obj:\n",
    "                return obj[\"text_sequence\"]\n",
    "            else:\n",
    "                output = \"\"\n",
    "                if sort_json_key:\n",
    "                    keys = sorted(obj.keys(), reverse=True)\n",
    "                else:\n",
    "                    keys = obj.keys()\n",
    "                for k in keys:\n",
    "                    output += rf\"\" + self.json2token(obj[k], sort_json_key) + rf\"\"\n",
    "                return output\n",
    "        elif type(obj) == list:\n",
    "            return r\"\".join([self.json2token(item, sort_json_key) for item in obj])\n",
    "        else:\n",
    "            obj = str(obj)\n",
    "            return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.types import DataPreset\n",
    "\n",
    "json_image_preset = DataPreset(\n",
    "    train_test_split=0.2,\n",
    "    path = \"fashion_twitter\",\n",
    "    collator_cls=ImageJSONCollatorWithPadding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_presets import paligemma_preset\n",
    "from src.train_builder import build_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = build_trainer(**json_image_preset.as_kwargs(), **paligemma_preset.as_kwargs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
